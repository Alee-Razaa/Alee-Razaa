{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgc0muyVFZ5NToJDvA0yyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alee-Razaa/Alee-Razaa/blob/main/Spam_detection_NLP_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngt1C3nqNlue",
        "outputId": "e718ee43-dd2b-4225-d85f-f9281dc9b228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy as sp\n",
        "nlp = sp.load('en_core_web_sm')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ynL6_YWIN6TJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/spam_ham_dataset.csv')"
      ],
      "metadata": {
        "id": "6vp9SWOiN6lY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenize and process the text\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remove stop words and punctuation, and lemmatize the tokens\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token in [\"\\n\",\"\\r\",\"^\"] ]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "Vo92jnQWRzcz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_text'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "szXA4OXfN6og",
        "outputId": "0f61a913-b432-4b15-e36a-7f9b234319f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-02d43d8ca135>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4762\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4763\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4764\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4766\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-fe3f965a556e>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Tokenize and process the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Remove stop words and punctuation, and lemmatize the tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/attributeruler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/attributeruler.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_spans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Sort by the attribute ID, so that later rules have precedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         matches = [\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "A6NQFyihN6uM",
        "outputId": "60baecf2-3603-4ef7-fd4c-f8517d2b5625"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Subject: enron methanol ; meter # : 988291\\r\\nthis is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\\r\\nflow data provided by daren } .\\r\\nplease override pop ' s daily volume { presently zero } to reflect daily\\r\\nactivity you can obtain from gas control .\\r\\nthis change is needed asap for economics purposes .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_text'][:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PNYeM8bX-RX",
        "outputId": "5f899fc8-52dd-4622-c129-d2fcc23bbd59"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    subject enron methanol meter 988291 \\r\\n follo...\n",
              "Name: cleaned_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-qITRXEZSn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLE6pjlzN6x1",
        "outputId": "1e14a7a8-f67a-463e-8410-5e2d13d23093"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5171, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.cleaned_text, df.label_num, test_size=0.2, random_state=42)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx1ph60FN61a",
        "outputId": "2c941fc7-4ceb-4a62-c1b2-45d5ab08daaa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5132    subject april activity survey \\r\\n start colle...\n",
              "2067    subject message subject \\r\\n hey julie ^ ^ tur...\n",
              "4716    subject txu fuel sds nomination 2001 \\r\\n atta...\n",
              "4710    subject richardson volume nov 99 dec 99 meter ...\n",
              "2268    subject new era online medical care \\r\\n new e...\n",
              "                              ...                        \n",
              "4426    subject ena sale hpl \\r\\n legal review contrac...\n",
              "466     subject tenaska iv \\r\\n bob \\r\\n understand sa...\n",
              "3092    subject broom bristle flew \\r\\n differentiable...\n",
              "3772    subject calpine daily gas nomination weekend \\...\n",
              "860     subject meter 1459 6 00 \\r\\n yep right s june ...\n",
              "Name: cleaned_text, Length: 4136, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpc05Tz1N65B",
        "outputId": "cdf721cf-b194-4dd7-ccff-708730978b35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5132    subject april activity survey \\r\\n start colle...\n",
              "2067    subject message subject \\r\\n hey julie ^ ^ tur...\n",
              "4716    subject txu fuel sds nomination 2001 \\r\\n atta...\n",
              "4710    subject richardson volume nov 99 dec 99 meter ...\n",
              "Name: cleaned_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqtp93YJZYzv",
        "outputId": "6b87be6d-d86d-4b81-ec4a-b153343efb9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['subject april activity survey \\r\\n start collect datum april attached survey drive \\r\\n cost activity commercial team select rcs \\r\\n fill driver quantity request driver month \\r\\n february fill attached activity driver survey april \\r\\n number rc end day thursday 4 th \\r\\n group currently generate standard report capture \\r\\n survey datum send report recipient \\r\\n list begin month eliminate need fill \\r\\n survey month like collect information \\r\\n team begin month let know \\r\\n contact lisa cousino x 3 6343 unable complete \\r\\n survey allotted time \\r\\n thank \\r\\n shari \\r\\n 3 3859',\n",
              "       'subject message subject \\r\\n hey julie ^ ^ turn 18 high school senior houston tx wait long time day finally get wish simply try meet new cyber friend know lead d don t worry usually online free age verification t younger snoop hehe \\r\\n http oioaz stuntscholar com ju 2 \\r\\n',\n",
              "       'subject txu fuel sds nomination 2001 \\r\\n attach 2001 nomination take gas sale \\r\\n purchase contract txu fuel company previously tufco sds \\r\\n advise question concern attached \\r\\n thank \\r\\n ccs \\r\\n attached file sdsnom xls \\r\\n sdsnom xls',\n",
              "       ...,\n",
              "       'subject broom bristle flew \\r\\n differentiable onomatopoeic infirm \\r\\n decompress organismic convertible \\r\\n sergei clergy irreversible \\r\\n windomitable postwar sod \\r\\n weekend asymptotic \\r\\n sberlioz arteriolosclerosis rhododendron \\r\\n tue 14 dec 2004 22 06 54 0600 \\r\\n dear applicant 7354 \\r\\n financial review situation q u alifie \\r\\n 3 3 deal ensure detail time offer \\r\\n follow secure \\r\\n link \\r\\n appreciate business \\r\\n sincerely \\r\\n keith kennedy oi associate \\r\\n beckon crusade icgdkxu \\r\\n wise jqbbstuc \\r\\n allemand itsfrom dandelion \\r\\n chocolate aforesaid blocky \\r\\n analgesic flux \\r\\n carrageen avenge gbfprzk \\r\\n cautionary em attestation pbtzdk \\r\\n alliterate kykubxxs \\r\\n aylesbury mug seld convulsion catatonic uvbzbeezt \\r\\n exempt workspace adult pennyroyal fourfold plvzdaotv \\r\\n stirrup thornton charcoal zealand tvjvwji \\r\\n parallelogram urooftop invigorate wallpaper onward winnie avdpbmlz \\r\\n vancouver xcalibre rsoft characteristic wymxcqu \\r\\n nonchalant octahedron palindrome \\r\\n contradistinction variac \\r\\n uavail cadenza isochronous citron frame \\r\\n polk gpa mickelson trjbascq \\r\\n segregate break accentual pillage beaux \\r\\n reactant jluminescent affor \\r\\n larkin perceive cold hmxfyoisv \\r\\n',\n",
              "       'subject calpine daily gas nomination weekend \\r\\n > \\r\\n ricky archer \\r\\n fuel supply \\r\\n 700 louisiana suite 2700 \\r\\n houston texas 77002 \\r\\n 713 830 8659 direct \\r\\n 713 830 8722 fax \\r\\n calpine daily gas nomination 1 doc',\n",
              "       'subject meter 1459 6 00 \\r\\n yep right s june 1999 let know \\r\\n ll tomorrow let carlos know \\r\\n set pop \\r\\n aimee \\r\\n daren j farmer \\r\\n 07 13 2000 01 16 pm \\r\\n aimee lannou hou ect ect \\r\\n cc \\r\\n subject meter 1459 6 00 \\r\\n deal 77352 june \\r\\n d \\r\\n aimee lannou 07 12 2000 02 00 pm \\r\\n daren j farmer hou ect ect \\r\\n cc \\r\\n subject meter 1459 6 00 \\r\\n daren need deal set meter 1459 june 00 flow 34 day \\r\\n 6 1 6 6 deal number 77352 ena let know \\r\\n set \\r\\n thank \\r\\n aimee'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIh8j0u1ZYv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "v = CountVectorizer()\n",
        "X_train_count = v.fit_transform(X_train)\n",
        "X_train_count.toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNduWE01ZSZ0",
        "outputId": "08aab616-904b-49a0-9fc6-d299465a2fa5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_count[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fWIxidRZ4Xm",
        "outputId": "d5ed3fe4-a894-43bf-943e-52469ad1cb6d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 41245)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Print the non zero values from the \"X_train_count.toarray()[0]\"\n",
        "\n",
        "# Get the non-zero values and their indices\n",
        "non_zero_indices = np.nonzero(X_train_count.toarray()[0])[0]\n",
        "non_zero_values = X_train_count.toarray()[0][non_zero_indices]\n",
        "\n",
        "# Print the non-zero values\n",
        "print(non_zero_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DmUWc3EaLF3",
        "outputId": "c9a4d840-a0a1-440b-9717-f97e6b0ffc22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 3 1 3 2 2 1 2 1 1 1 1 1 1 2 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 4 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 6 2 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_count = v.transform(X_test)\n",
        "X_test_count.toarray()[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI6cNWYBZSc2",
        "outputId": "e4a976ad-5565-43d5-fab5-364573249347"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Train a Naive Bayes classifier on the vectorized training data\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_count, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "c4R12LW6ZSgp",
        "outputId": "6c45cfa0-9cb5-49d4-f3fc-298ea5f65a52"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Predict the labels for the test data\n",
        "y_pred = model.predict(X_test_count)"
      ],
      "metadata": {
        "id": "_b7E1hvnZSkR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15: Evaluate the model using classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COHCfZrod8d0",
        "outputId": "aeb0cf25-4579-4e77-a90a-5e579b3597d5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       742\n",
            "           1       0.94      0.95      0.95       293\n",
            "\n",
            "    accuracy                           0.97      1035\n",
            "   macro avg       0.96      0.96      0.96      1035\n",
            "weighted avg       0.97      0.97      0.97      1035\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "AWg9DaAjiyWc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "pemWA4vrjQYk",
        "outputId": "c1432327-b847-4cdc-edfc-a8c517ab2d7d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer()), ('nb', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyiYV4f8jURz",
        "outputId": "38c721ce-02a2-4c87-ee15-71ead21cc456"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       742\n",
            "           1       0.94      0.95      0.95       293\n",
            "\n",
            "    accuracy                           0.97      1035\n",
            "   macro avg       0.96      0.96      0.96      1035\n",
            "weighted avg       0.97      0.97      0.97      1035\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained pipeline to a file\n",
        "import joblib\n",
        "joblib.dump(pipeline, 'spam_classifier_pipeline.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y60yCUEUd8hy",
        "outputId": "74e89895-6510-4f15-8077-b467db9d59c3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spam_classifier_pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file\n",
        "loaded_pipeline = joblib.load('spam_classifier_pipeline.pkl')\n"
      ],
      "metadata": {
        "id": "TwcWVPtFd8z-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to get important words for spam classification\n",
        "def get_important_words_count_vectorizer(pipeline, class_label=1, top_n=20):\n",
        "    # Extract the vectorizer and model from the pipeline\n",
        "    vectorizer = pipeline.named_steps['vectorizer']\n",
        "    model = pipeline.named_steps['nb']\n",
        "\n",
        "    # Get feature names and feature importances (log probabilities) from the model\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    class_probabilities = model.feature_log_prob_[class_label]\n",
        "\n",
        "    # Create a DataFrame to hold feature names and their corresponding probabilities\n",
        "    feature_probs = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Log Probability': class_probabilities\n",
        "    })\n",
        "\n",
        "    # Sort by log probability and get top_n features\n",
        "    top_features = feature_probs.sort_values(by='Log Probability', ascending=False).head(top_n)\n",
        "\n",
        "    return top_features"
      ],
      "metadata": {
        "id": "ITV39J9Tmoek"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    filtered_text = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return ' '.join(filtered_text)\n",
        "\n",
        "def get_contributing_words(pipeline, email_text, class_label=1):\n",
        "    # Preprocess the email text\n",
        "    preprocessed_text = preprocess_text(email_text)\n",
        "\n",
        "    # Extract the vectorizer and model from the pipeline\n",
        "    vectorizer = pipeline.named_steps['vectorizer']\n",
        "    model = pipeline.named_steps['nb']\n",
        "\n",
        "    # Transform the email text using the vectorizer\n",
        "    X_transformed = vectorizer.transform([preprocessed_text])\n",
        "\n",
        "    # Get feature names\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Get the log probabilities for the specific class\n",
        "    class_probabilities = model.feature_log_prob_[class_label]\n",
        "\n",
        "    # Get the feature indices for the email text\n",
        "    feature_indices = X_transformed.indices\n",
        "\n",
        "    # Get the corresponding feature names and their log probabilities\n",
        "    feature_probs = {\n",
        "        feature_names[i]: class_probabilities[i]\n",
        "        for i in feature_indices\n",
        "    }\n",
        "\n",
        "    # Sort features by their log probabilities\n",
        "    sorted_features = sorted(feature_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return sorted_features\n"
      ],
      "metadata": {
        "id": "KiIWv6JQox3r"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_text1 = \"\"\"\n",
        "The day has come. We’ve made it.  🎉\n",
        "\n",
        "Your input has helped us understand how to fully round out and shape the future of Lumen5. After many months of hard work and valuable feedback from our amazing community (yes, that includes you!), we are thrilled to announce the our AI Voiceover feature is out of beta.\n",
        "\n",
        "What does this mean? We have officially unveiled this engaging new type of video and all its features. Here’s a quick rundown:\n",
        "\n",
        "Choose a stock AI voice from our marketplace\n",
        "\n",
        "Browse through our selection of human-like AI voices, each with descriptors such as gender, name, accent, and tone/mood. Select the voice that best fits your video’s narrative and audience. Not sure which one to pick? Or what’s the difference between them all? Read more about how to pick the right voice for your video.\n",
        "\n",
        "Or upload and clone your own (branded) voice\n",
        "\n",
        "For Enterprise creators, if you have a specific voice associated with your brand, you can upload it for a personalized touch. This ensures consistency and familiarity for your audience. Record and upload a sample recording and let our AI do the rest. The cloned voice can be used for future videos and beyond!\n",
        "\n",
        "Or create a custom one-of-a-kind AI voice\n",
        "\n",
        "For a truly unique voice, create a custom AI voice tailored to your brand’s personality. This option offers the highest level of voiceover customization and brand alignment and is offered to Enterprise level teams. If you’re interested, please feel free to book a demo.\n",
        "\n",
        "Book a demo\n",
        "Generate and recommend video scenes\n",
        "\n",
        "Lumen5’s AI will recommend video scenes for you! Generating an entirely new video for you based on your voiceover transcript, this feature will save you tons of time and create consistent results.\n",
        "\n",
        "Regenerate and swap parts of the voiceover\n",
        "\n",
        "If any phrases are pronounced incorrectly, you can easily regenerate those parts until you achieve the desired pronunciation. It’s easy, here’s how.\n",
        "\n",
        "Or if you’re not satisfied with your initial voice choice, swap the voice entirely and experiment with different options until you’re happy with the final output. We’ve outlined it here for you.\n",
        "\n",
        "Editing the transcript\n",
        "\n",
        "Inspiration can strike at any moment. Editing multiple words or large chunks of the transcript is now available. Whether you want to tweak the tone, adjust the pacing, or refine the wording, you have the power to perfect your message without starting from scratch. To edit, highlight the section you’d like to edit in the transcript and make your desired changes. And ta-da! The voiceover will automatically regenerate itself to match the transcript.\n",
        "\n",
        "And that’s everything to it. Looking for a more in-depth breakdown? Here’s our help guide for AI Voiceover Videos.\n",
        "\n",
        "We hope you like it,\n",
        "\n",
        "Kaegan and the Lumen5 Product Team\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "z_1PiBgrpxP8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfwVathJqN8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_text2 = \"\"\"\n",
        "Hi Team,\n",
        "\n",
        "I hope this email finds you well.\n",
        "\n",
        "I wanted to follow up on the project we discussed last week. I have attached the updated draft of the report, which includes the latest data and analysis. Please review it at your earliest convenience and let me know if there are any additional changes or if you have any questions.\n",
        "\n",
        "Additionally, could we schedule a brief meeting next week to go over the final details before the presentation? I am available on Tuesday and Thursday afternoon. Please let me know which time works best for you.\n",
        "\n",
        "Thank you for your attention to this matter. I look forward to your feedback.\n",
        "\n",
        "Best regards,\n",
        "\n",
        "Alex Johnson\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "bWp3gC7jqNiJ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_text3 = \"\"\"Join us Thursday, August 8 at 12:00 PM MT\n",
        "Join CU Boulder on Thursday, August 8 at noon MT, to learn about their MS in Data Science program. You’ll hear about performance-based admissions, the interdisciplinary curriculum, and career outcomes for this 100% online degree program.\n",
        "\n",
        "Secure your spot today!\n",
        "\n",
        "\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "dF9VYHUDtIee"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_text4 = \"\"\"As Andrew Ng recently noted, \"AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models.\"\n",
        "\n",
        "In line with this pivotal trend, we’ve launched a series of short courses to help you build and implement AI agents through hands-on lessons, while gaining experience with leading frameworks like crewAI, AutoGen, and LangGraph. Many of these are beginner friendly, with just basic Python as a prerequisite recommendation. Check out our available short courses on AI agents!\n",
        "\n",
        "Multi AI Agent Systems with crewAI\n",
        "\n",
        "Taught by João Moura, founder and CEO of crewAI, Multi AI Agent Systems with crewAI will teach you key components of AI agents, and how to assign specialized roles to agents and coordinate their efforts for optimal performance.\n",
        "\n",
        "With crewAI, an open source library for building multi-agent systems, you'll get hands-on experience building agent crews for processes like tailoring resumes and interview prep for job applications, researching, writing, and editing technical articles, conducting customer outreach campaigns and financial analysis, planning events, and more.\n",
        "\n",
        "You’ll design and prompt a team of agents through natural language to automate your business workflows, exceeding the performance of prompting a single LLM.\n",
        "\n",
        "Enroll for free\n",
        "\n",
        "AI Agents in LangGraph\n",
        "\n",
        "LangGraph allows developers to create highly controllable agents.\n",
        "\n",
        "In AI Agents in LangGraph you will learn to build an agent from scratch using Python and an LLM, and then you will rebuild it using LangGraph, learning about its components and how to combine them to build flow-based applications.\n",
        "\n",
        "Additionally, you will learn about agentic search, which returns multiple answers in an agent-friendly format, enhancing the agent’s built-in knowledge. This course will show you how to use agentic search in your applications to provide better data for agents to enhance their output.\n",
        "\n",
        "Enroll for free\n",
        "\n",
        "Building Agentic RAG with LlamaIndex\n",
        "\n",
        "In this course made in collaboration with LlamaIndex and taught by its co-founder and CEO, Jerry Liu, you'll build agents capable of intelligently navigating, summarizing, and comparing information across multiple research papers from arXiv, and learn how to debug these agents, ensuring you can guide their actions effectively.\n",
        "\n",
        "Unlike the standard retrieval augmented generation (RAG) pipeline—suitable for simple queries across a few documents—agentic RAG adapts based on initial findings to enhance further data retrieval. In Building Agentic RAG with LlamaIndex, you'll use this framework to build research agents skilled in tool use, reasoning, and decision-making with your data.\n",
        "\n",
        "Enroll for free\n",
        "\n",
        "AI Agentic Design Patterns with AutoGen\n",
        "\n",
        "This short course was made in collaboration with Microsoft and Penn State University, and is taught by AutoGen creators Chi Wang, Principal Researcher at Microsoft Research, and Qingyun Wu, Assistant Professor at Penn State University.\n",
        "\n",
        "In AI Agentic Design Patterns with AutoGen, you’ll learn how to build and customize multi-agent systems, enabling agents to take on different roles and collaborate to accomplish complex tasks using AutoGen, a framework that enables the development of LLM applications using multi-agents, all while implementing four agentic design patterns: Reflection, Tool use, Planning, and Multi-agent collaboration using AutoGen.\n",
        "\n",
        "Enroll for free\n",
        "\n",
        "Looking for more? Check out all AI short courses from DeepLearning.AI\n",
        "\n",
        "Keep learning,\n",
        "\n",
        "- The DeepLearning.AI team \"\"\""
      ],
      "metadata": {
        "id": "Y3EGacqJxwHO"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example email text\n",
        "email_text = \"\"\"\n",
        "Hi there,\n",
        "\n",
        "I have a Lamborghini that can only go 5 MPH.\n",
        "\n",
        "That's what it felt knowing my brain moves fast but, because my reading was slow, I couldn't learn fast.\n",
        "\n",
        "I'd feel frustrated and honestly, felt like a failure.\n",
        "\n",
        "I remember, when I was 10 years old, I wanted to be the President, a billionaire, and a pop star all at the same time.\n",
        "\n",
        "But, I realized that to do this… I needed to be able to read and learn fast.\n",
        "\n",
        "If you keep reading… I'm gonna give you the secrets I learned to learn anything 10x faster…\n",
        "\n",
        ">>> Click here to join the How to Learn Anything 10x Faster training\n",
        "\n",
        "I used these secrets to eventually become one of the youngest people on the Forbes 30 Under 30 list and build products that over 40 million people use today.\n",
        "\n",
        "I'm not saying this to brag, but just to share with you that learning how to learn faster… is worth the effort.\n",
        "\n",
        "When I was 9 years old, my dad canceled my birthday party.\n",
        "\n",
        "I was lying to my parents about reading books. I desperately wanted to be like my dad. He was my hero. I wanted him to be proud of me. He cared so much about me reading, but I found it so slow, so boring, so difficult.\n",
        "\n",
        "Every day, I'd pretend to read. I’d sit with the dead tree in my hands, looking at the page. But, I read so slowly that it was less painful to sit and do nothing than to actually read.\n",
        "\n",
        "When my dad discovered I lied, he canceled my birthday party.\n",
        "\n",
        "I cried. Not just because of the party, but because I wasn’t becoming who I wanted to be. My parents thought I was lazy.\n",
        "\n",
        "I was going to be who I wanted to be. I was going to figure out reading. So for that school break, all I did was read.\n",
        "\n",
        "No TV, no playing outside, just books. I'd spend hours in the public library, trying to force myself through pages.\n",
        "\n",
        "I'd fall asleep my nose buried in the 4th page of Harry Potter. The librarian would have to wake me up.\n",
        "\n",
        "I was determined to brute force my way through. Then, something changed.\n",
        "\n",
        "My dad started reading to me. He even began recording books on his cassette player for me to listen to. I’d fall asleep listening to his voice.\n",
        "\n",
        "I learned how to download audiobooks from the internet. Suddenly, I could \"read\" while brushing my teeth, biking, or walking.\n",
        "\n",
        "Between the ages of 13 and 30 I averaged reading 2 books a week. More than 2,000 books in total. I got into an Ivy League college, became fluent in English, and learned how to code. Learning fast became my superpower. It completely changed the trajectory of my life.\n",
        "\n",
        "This is why I'm so passionate about sharing tools like Speechify. I want every person to experience the same transformation I did.\n",
        "\n",
        "Learning how to learn faster isn't just a skill – it's a life-changer. I'm here to show you how to do it.\n",
        "\n",
        "I saw that you signed up to use Speechify but never figured out how to use it well. I'd love to teach you how.\n",
        "\n",
        "This week, I'm putting together a training on \"How to Learn Anything 10x Faster\" where we'll deep dive into:\n",
        "\n",
        "- How to Read / Learn 3x Faster (including YouTube videos)\n",
        "- 1 Secret for Unlocking 1.5x Higher Memory\n",
        "- 3 ADHD focus secrets for never getting distracted while reading\n",
        "- How to read PDFs & Kindle eBooks on Speechify\n",
        "- Using AI to summarize documents\n",
        "- Why 40% of Billionaires have Dyslexia & how it could be your superpower\n",
        "\n",
        "I know how it feels to be overwhelmed with all the stuff we need to learn. But what if you could learn things way faster? Think about how much more you could do.\n",
        "\n",
        "This isn't just about reading books faster. It's about learning anything fast: for work, school, or just things you're interested in.\n",
        "\n",
        "I've been where you are, and these tricks have made a huge difference for me.\n",
        "\n",
        "That's why I'm so excited to share them with you.\n",
        "\n",
        "We can do this together, and I really think this training could help you a lot.\n",
        "\n",
        "So, want to give it a shot?\n",
        "\n",
        "Let's learn how to learn faster, together.\n",
        "\n",
        "I think you'll be amazed at what you can do.\n",
        "\n",
        ">>> Click here to join the How to Learn Anything 10x Faster training\n",
        "\n",
        "Much love 💙,\n",
        "Cliff\n",
        "\"\"\"\n",
        "# Use the loaded model to make a prediction\n",
        "prediction = loaded_pipeline.predict([email_text4])\n",
        "\n",
        "# Interpret the prediction\n",
        "is_spam = bool(prediction[0])\n",
        "print(\"Spam\" if is_spam else \"Not Spam\")\n",
        "\n",
        "# Predict and evaluate on the test set\n",
        "y_pred = loaded_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24tac56md844",
        "outputId": "e1daf118-11c6-4cf3-f921-0d9476f82e98"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       742\n",
            "           1       0.94      0.95      0.95       293\n",
            "\n",
            "    accuracy                           0.97      1035\n",
            "   macro avg       0.96      0.96      0.96      1035\n",
            "weighted avg       0.97      0.97      0.97      1035\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print the words contributing to spam classification\n",
        "contributing_words = get_contributing_words(loaded_pipeline, email_text4)\n",
        "print(\"Words contributing to spam classification:\")\n",
        "for word, prob in contributing_words:\n",
        "    print(f\"{word}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwG6-wytd89N",
        "outputId": "00c1a0aa-011b-4ef1-cd98-8f0d730774ab"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words contributing to spam classification:\n",
            "information: -6.0283\n",
            "look: -6.3693\n",
            "free: -6.5271\n",
            "business: -6.6665\n",
            "like: -6.8592\n",
            "provide: -6.8961\n",
            "use: -6.8961\n",
            "year: -6.9401\n",
            "microsoft: -6.9457\n",
            "line: -6.9628\n",
            "system: -6.9802\n",
            "base: -7.0784\n",
            "available: -7.0849\n",
            "customer: -7.2543\n",
            "event: -7.2698\n",
            "performance: -7.3344\n",
            "source: -7.3427\n",
            "help: -7.5067\n",
            "action: -7.5575\n",
            "process: -7.5575\n",
            "check: -7.6792\n",
            "note: -7.7398\n",
            "well: -7.7524\n",
            "state: -7.7651\n",
            "drive: -7.7911\n",
            "financial: -7.8452\n",
            "application: -7.9630\n",
            "experience: -8.0614\n",
            "lead: -8.0614\n",
            "natural: -8.0614\n",
            "design: -8.0788\n",
            "development: -8.1145\n",
            "format: -8.1329\n",
            "gain: -8.1329\n",
            "build: -8.1516\n",
            "effort: -8.1900\n",
            "open: -8.2300\n",
            "create: -8.2506\n",
            "allow: -8.3152\n",
            "team: -8.3152\n",
            "return: -8.3377\n",
            "learn: -8.3606\n",
            "agent: -8.3842\n",
            "enhance: -8.3842\n",
            "co: -8.4330\n",
            "document: -8.4330\n",
            "compare: -8.4843\n",
            "datum: -8.4843\n",
            "search: -8.4843\n",
            "short: -8.4843\n",
            "highly: -8.5383\n",
            "research: -8.5383\n",
            "tool: -8.5383\n",
            "key: -8.6253\n",
            "paper: -8.6879\n",
            "model: -8.7206\n",
            "simple: -8.7206\n",
            "ng: -8.7896\n",
            "campaign: -8.8260\n",
            "answer: -8.8637\n",
            "multi: -8.9030\n",
            "multiple: -8.9030\n",
            "standard: -8.9030\n",
            "ceo: -8.9438\n",
            "enable: -8.9438\n",
            "generation: -8.9438\n",
            "decision: -8.9863\n",
            "recently: -8.9863\n",
            "course: -9.0308\n",
            "different: -9.0308\n",
            "ensure: -9.0308\n",
            "hand: -9.0308\n",
            "guide: -9.1261\n",
            "single: -9.1261\n",
            "massive: -9.1774\n",
            "initial: -9.2886\n",
            "customize: -9.3493\n",
            "flow: -9.3493\n",
            "job: -9.3493\n",
            "automate: -9.4828\n",
            "conduct: -9.4828\n",
            "recommendation: -9.4828\n",
            "article: -9.6369\n",
            "developer: -9.6369\n",
            "exceed: -9.7239\n",
            "language: -9.7239\n",
            "launch: -9.7239\n",
            "teach: -9.7239\n",
            "combine: -9.8193\n",
            "edit: -9.8193\n",
            "output: -9.8193\n",
            "accomplish: -9.9246\n",
            "component: -9.9246\n",
            "debug: -9.9246\n",
            "knowledge: -9.9246\n",
            "task: -9.9246\n",
            "complex: -10.0424\n",
            "prompt: -10.0424\n",
            "series: -10.0424\n",
            "technical: -10.0424\n",
            "trend: -10.0424\n",
            "university: -10.0424\n",
            "analysis: -10.1759\n",
            "crew: -10.1759\n",
            "effectively: -10.1759\n",
            "additionally: -10.3301\n",
            "assign: -10.3301\n",
            "building: -10.3301\n",
            "capable: -10.3301\n",
            "principal: -10.3301\n",
            "role: -10.3301\n",
            "assistant: -10.5124\n",
            "creator: -10.5124\n",
            "foundation: -10.5124\n",
            "founder: -10.5124\n",
            "friendly: -10.5124\n",
            "library: -10.5124\n",
            "pattern: -10.5124\n",
            "resume: -10.5124\n",
            "andrew: -10.7355\n",
            "basic: -10.7355\n",
            "collaboration: -10.7355\n",
            "controllable: -10.7355\n",
            "framework: -10.7355\n",
            "interview: -10.7355\n",
            "lesson: -10.7355\n",
            "pipeline: -10.7355\n",
            "pivotal: -10.7355\n",
            "professor: -10.7355\n",
            "progress: -10.7355\n",
            "python: -10.7355\n",
            "retrieval: -10.7355\n",
            "suitable: -10.7355\n",
            "adapt: -11.0232\n",
            "augment: -11.0232\n",
            "beginner: -11.0232\n",
            "collaborate: -11.0232\n",
            "implement: -11.0232\n",
            "planning: -11.0232\n",
            "query: -11.0232\n",
            "skilled: -11.0232\n",
            "systems: -11.0232\n",
            "unlike: -11.0232\n",
            "writing: -11.0232\n",
            "wu: -11.0232\n",
            "ai: -11.4287\n",
            "coordinate: -11.4287\n",
            "finding: -11.4287\n",
            "jerry: -11.4287\n",
            "penn: -11.4287\n",
            "rag: -11.4287\n",
            "rebuild: -11.4287\n",
            "reflection: -11.4287\n",
            "researcher: -11.4287\n",
            "scratch: -11.4287\n",
            "specialized: -11.4287\n",
            "tailor: -11.4287\n",
            "chi: -12.1218\n",
            "enroll: -12.1218\n",
            "making: -12.1218\n",
            "navigate: -12.1218\n",
            "optimal: -12.1218\n",
            "prerequisite: -12.1218\n",
            "wang: -12.1218\n",
            "workflow: -12.1218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOk9Iq4od9BD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}